{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#Import Necessary Libraries\nimport string\nfrom collections import Counter\nimport pandas as pd\nimport numpy as np\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\n\nimport torch\nimport torch.nn as nn\nimport torchtext\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.model_selection import train_test_split","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-05T16:57:01.833362Z","iopub.execute_input":"2023-11-05T16:57:01.833721Z","iopub.status.idle":"2023-11-05T16:57:01.839510Z","shell.execute_reply.started":"2023-11-05T16:57:01.833686Z","shell.execute_reply":"2023-11-05T16:57:01.838532Z"},"trusted":true},"execution_count":133,"outputs":[]},{"cell_type":"code","source":"#read data\ndf = pd.read_csv(\"/kaggle/input/symptom2disease/Symptom2Disease.csv\")\ndf.drop(\"Unnamed: 0\",inplace=True,axis=1)\ndf","metadata":{"execution":{"iopub.status.busy":"2023-11-05T16:51:48.990505Z","iopub.execute_input":"2023-11-05T16:51:48.991252Z","iopub.status.idle":"2023-11-05T16:51:49.020082Z","shell.execute_reply.started":"2023-11-05T16:51:48.991216Z","shell.execute_reply":"2023-11-05T16:51:49.019160Z"},"trusted":true},"execution_count":124,"outputs":[{"execution_count":124,"output_type":"execute_result","data":{"text/plain":"          label                                               text\n0     Psoriasis  I have been experiencing a skin rash on my arm...\n1     Psoriasis  My skin has been peeling, especially on my kne...\n2     Psoriasis  I have been experiencing joint pain in my fing...\n3     Psoriasis  There is a silver like dusting on my skin, esp...\n4     Psoriasis  My nails have small dents or pits in them, and...\n...         ...                                                ...\n1195   diabetes  I'm shaking and trembling all over. I've lost ...\n1196   diabetes  Particularly in the crevices of my skin, I hav...\n1197   diabetes  I regularly experience these intense urges and...\n1198   diabetes  I have trouble breathing, especially outside. ...\n1199   diabetes  I constantly sneeze and have a dry cough. My i...\n\n[1200 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Psoriasis</td>\n      <td>I have been experiencing a skin rash on my arm...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Psoriasis</td>\n      <td>My skin has been peeling, especially on my kne...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Psoriasis</td>\n      <td>I have been experiencing joint pain in my fing...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Psoriasis</td>\n      <td>There is a silver like dusting on my skin, esp...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Psoriasis</td>\n      <td>My nails have small dents or pits in them, and...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1195</th>\n      <td>diabetes</td>\n      <td>I'm shaking and trembling all over. I've lost ...</td>\n    </tr>\n    <tr>\n      <th>1196</th>\n      <td>diabetes</td>\n      <td>Particularly in the crevices of my skin, I hav...</td>\n    </tr>\n    <tr>\n      <th>1197</th>\n      <td>diabetes</td>\n      <td>I regularly experience these intense urges and...</td>\n    </tr>\n    <tr>\n      <th>1198</th>\n      <td>diabetes</td>\n      <td>I have trouble breathing, especially outside. ...</td>\n    </tr>\n    <tr>\n      <th>1199</th>\n      <td>diabetes</td>\n      <td>I constantly sneeze and have a dry cough. My i...</td>\n    </tr>\n  </tbody>\n</table>\n<p>1200 rows Ã— 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# set of English stopwords we will remove from our text data\nstop_words = set(stopwords.words('english'))","metadata":{"execution":{"iopub.status.busy":"2023-11-05T16:52:27.767145Z","iopub.execute_input":"2023-11-05T16:52:27.767862Z","iopub.status.idle":"2023-11-05T16:52:27.772799Z","shell.execute_reply.started":"2023-11-05T16:52:27.767825Z","shell.execute_reply":"2023-11-05T16:52:27.771804Z"},"trusted":true},"execution_count":125,"outputs":[]},{"cell_type":"code","source":"def clean_text(sent):\n    #remove punctuations\n    sent = sent.translate(str.maketrans('','',string.punctuation)).strip()\n    \n    #remove stopwords\n    stop_words = set(stopwords.words('english'))\n    words = word_tokenize(sent)\n    words = [word for word in words if word not in stop_words]\n    \n    return \" \".join(words).lower()","metadata":{"execution":{"iopub.status.busy":"2023-11-05T16:52:31.855317Z","iopub.execute_input":"2023-11-05T16:52:31.855994Z","iopub.status.idle":"2023-11-05T16:52:31.861374Z","shell.execute_reply.started":"2023-11-05T16:52:31.855957Z","shell.execute_reply":"2023-11-05T16:52:31.860477Z"},"trusted":true},"execution_count":126,"outputs":[]},{"cell_type":"code","source":"# clean text rows in dataframe\ndf[\"text\"] = df[\"text\"].apply(clean_text)","metadata":{"execution":{"iopub.status.busy":"2023-11-05T16:53:05.159487Z","iopub.execute_input":"2023-11-05T16:53:05.160364Z","iopub.status.idle":"2023-11-05T16:53:05.738489Z","shell.execute_reply.started":"2023-11-05T16:53:05.160328Z","shell.execute_reply":"2023-11-05T16:53:05.737708Z"},"trusted":true},"execution_count":127,"outputs":[]},{"cell_type":"code","source":"# get list of diseases in our dataset\ndiseases = df[\"label\"].unique()\n\n# helper dictionaries to convert diseases to index and vice versa\nidx2dis = {k:v for k,v in enumerate(diseases)}\ndis2idx = {v:k for k,v in idx2dis.items()}","metadata":{"execution":{"iopub.status.busy":"2023-11-05T16:53:52.321094Z","iopub.execute_input":"2023-11-05T16:53:52.321847Z","iopub.status.idle":"2023-11-05T16:53:52.328486Z","shell.execute_reply.started":"2023-11-05T16:53:52.321806Z","shell.execute_reply":"2023-11-05T16:53:52.327262Z"},"trusted":true},"execution_count":128,"outputs":[]},{"cell_type":"code","source":"# convert disease name to index (label encoding)\ndf[\"label\"] = df[\"label\"].apply(lambda x: dis2idx[x])","metadata":{"execution":{"iopub.status.busy":"2023-11-05T16:54:38.828579Z","iopub.execute_input":"2023-11-05T16:54:38.829348Z","iopub.status.idle":"2023-11-05T16:54:38.835205Z","shell.execute_reply.started":"2023-11-05T16:54:38.829309Z","shell.execute_reply":"2023-11-05T16:54:38.834129Z"},"trusted":true},"execution_count":129,"outputs":[]},{"cell_type":"code","source":"# Split the data into train,test set\nX_train, X_test, y_train, y_test = train_test_split(df[\"text\"], df[\"label\"], test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-11-05T16:55:14.913014Z","iopub.execute_input":"2023-11-05T16:55:14.913681Z","iopub.status.idle":"2023-11-05T16:55:14.919859Z","shell.execute_reply.started":"2023-11-05T16:55:14.913630Z","shell.execute_reply":"2023-11-05T16:55:14.918913Z"},"trusted":true},"execution_count":130,"outputs":[]},{"cell_type":"code","source":"# pytorch dataset object use index to return item, so need to reset non-continuoues index of divided dataset\nX_train.reset_index(drop=True, inplace=True)\nX_test.reset_index(drop=True, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-11-05T16:56:14.101770Z","iopub.execute_input":"2023-11-05T16:56:14.102569Z","iopub.status.idle":"2023-11-05T16:56:14.107575Z","shell.execute_reply.started":"2023-11-05T16:56:14.102526Z","shell.execute_reply":"2023-11-05T16:56:14.106536Z"},"trusted":true},"execution_count":131,"outputs":[]},{"cell_type":"code","source":"# max number of words in symptoms descriptions (cleaned version)\nmax_words = X_train.apply(lambda x:x.split()).apply(len).max()\nmax_words","metadata":{"execution":{"iopub.status.busy":"2023-11-05T16:56:46.267709Z","iopub.execute_input":"2023-11-05T16:56:46.268609Z","iopub.status.idle":"2023-11-05T16:56:46.278499Z","shell.execute_reply.started":"2023-11-05T16:56:46.268573Z","shell.execute_reply":"2023-11-05T16:56:46.277608Z"},"trusted":true},"execution_count":132,"outputs":[{"execution_count":132,"output_type":"execute_result","data":{"text/plain":"31"},"metadata":{}}]},{"cell_type":"code","source":"# create vocabulart using torchtext vocab class\ncounter = Counter()\nfor text in X_train:\n    counter.update(text.split())\n\nvocab = torchtext.vocab.vocab(counter,specials=['<unk>', '<pad>'])","metadata":{"execution":{"iopub.status.busy":"2023-11-05T16:57:36.924327Z","iopub.execute_input":"2023-11-05T16:57:36.925153Z","iopub.status.idle":"2023-11-05T16:57:37.011156Z","shell.execute_reply.started":"2023-11-05T16:57:36.925115Z","shell.execute_reply":"2023-11-05T16:57:37.010060Z"},"trusted":true},"execution_count":134,"outputs":[]},{"cell_type":"code","source":"# set default index as unknown token\nvocab.set_default_index(vocab['<unk>'])","metadata":{"execution":{"iopub.status.busy":"2023-11-05T16:58:00.224419Z","iopub.execute_input":"2023-11-05T16:58:00.225373Z","iopub.status.idle":"2023-11-05T16:58:00.229578Z","shell.execute_reply.started":"2023-11-05T16:58:00.225337Z","shell.execute_reply":"2023-11-05T16:58:00.228616Z"},"trusted":true},"execution_count":135,"outputs":[]},{"cell_type":"code","source":"# Create a PyTorch dataset`\nclass DiseaseDataset(torch.utils.data.Dataset):\n    def __init__(self, symptoms,labels):\n        self.symptoms = symptoms\n        self.labels= torch.tensor(labels.to_numpy())\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        text = self.symptoms[idx]\n        label = self.labels[idx]\n\n        # Convert the text to a sequence of word indices\n        text_indices = [vocab[word] for word in text.split()]\n        \n        # padding for same length sequence\n        if len(text_indices)<max_words:\n            text_indices = text_indices + [1]*(max_words - len(text_indices))\n        \n        return torch.tensor(text_indices), label","metadata":{"execution":{"iopub.status.busy":"2023-11-05T16:58:37.923862Z","iopub.execute_input":"2023-11-05T16:58:37.924562Z","iopub.status.idle":"2023-11-05T16:58:37.931457Z","shell.execute_reply.started":"2023-11-05T16:58:37.924523Z","shell.execute_reply":"2023-11-05T16:58:37.930517Z"},"trusted":true},"execution_count":136,"outputs":[]},{"cell_type":"code","source":"# instantiate dataset objects\ntrain_dataset = DiseaseDataset(X_train, y_train)\nval_dataset = DiseaseDataset(X_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2023-11-05T16:58:48.568666Z","iopub.execute_input":"2023-11-05T16:58:48.569022Z","iopub.status.idle":"2023-11-05T16:58:48.574499Z","shell.execute_reply.started":"2023-11-05T16:58:48.568994Z","shell.execute_reply":"2023-11-05T16:58:48.573572Z"},"trusted":true},"execution_count":137,"outputs":[]},{"cell_type":"code","source":"# choose batch size, will start from smaller values as we got smaller dataset\nbatch_size = 8\n\n# Create data loaders\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2023-11-05T17:04:14.838431Z","iopub.execute_input":"2023-11-05T17:04:14.838910Z","iopub.status.idle":"2023-11-05T17:04:14.844211Z","shell.execute_reply.started":"2023-11-05T17:04:14.838873Z","shell.execute_reply":"2023-11-05T17:04:14.843166Z"},"trusted":true},"execution_count":156,"outputs":[]},{"cell_type":"code","source":"# Define the RNN model\nclass RNNModel(torch.nn.Module):\n    def __init__(self, vocab_size, embedding_dim, hidden_dim,num_classes,drop_prob,num_layers=1,bidir=False,seq=\"lstm\"):\n        super(RNNModel, self).__init__()\n        self.seq = seq\n        self.bidir_f = 2 if bidir else 0\n        self.embedding = torch.nn.Embedding(vocab_size, embedding_dim)\n        if seq==\"lstm\":\n            self.rnn = torch.nn.LSTM(embedding_dim, hidden_dim,\n                                     num_layers=num_layers,\n                                     batch_first=True,\n                                     bidirectional=bidir)\n        else:\n            self.rnn = torch.nn.GRU(embedding_dim, hidden_dim,\n                                 num_layers=num_layers,\n                                 batch_first=True,\n                                bidirectional=bidir)\n        \n        self.dropout = torch.nn.Dropout(drop_prob) #dropout layer\n        self.fc = torch.nn.Linear(hidden_dim*self.bidir_f, num_classes) # fully connected layer\n\n    def forward(self, text_indices):\n        # Embed the text indices\n        embedded_text = self.embedding(text_indices)\n#         print(\"EMB SHAPE: \",embedded_text.shape)\n\n        # Pass the embedded text through the RNN\n        rnn_output,hidden_states = self.rnn(embedded_text)\n        # Take the last output of the RNN\n        last_rnn_output = rnn_output[:, -1, :]\n        x = self.dropout(last_rnn_output)\n        # Pass the last output of the RNN through the fully connected layer\n        x = self.fc(x)\n\n        # Return the final output\n        return x","metadata":{"execution":{"iopub.status.busy":"2023-11-05T17:06:10.467106Z","iopub.execute_input":"2023-11-05T17:06:10.467434Z","iopub.status.idle":"2023-11-05T17:06:10.476982Z","shell.execute_reply.started":"2023-11-05T17:06:10.467407Z","shell.execute_reply":"2023-11-05T17:06:10.476140Z"},"trusted":true},"execution_count":165,"outputs":[]},{"cell_type":"code","source":"def train(model,num_epochs=10):\n    criterion = nn.CrossEntropyLoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n    \n    #choose device for training\n    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n    model = model.cuda()\n    print(\"IS CUDA: \",next(model.parameters()).is_cuda)\n    \n    # Training loop\n    for epoch in range(num_epochs):\n        model.train()\n        for data in train_loader:\n            inputs,labels = data \n            inputs,labels = inputs.to(device), labels.to(device)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            acc = (labels == outputs.argmax(dim=-1)).float().mean().item()\n            loss.backward()\n            optimizer.step()\n\n        # Validation\n        model.eval()\n        with torch.no_grad():\n            val_loss = 0.0\n            correct = 0\n            total = 0\n            for inputs, labels in val_loader:\n                inputs,labels = inputs.to(device), labels.to(device)\n                outputs = model(inputs)\n                loss = criterion(outputs, labels)\n                val_loss += loss.item()\n                predicted = outputs.argmax(-1)\n                total += labels.size(0)\n                correct += (predicted == labels).sum().item()\n        accuracy = (labels == outputs.argmax(dim=-1)).float().mean().item()\n        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {val_loss}, Train Accuracy: {acc:.2f}  Val Accuracy: {accuracy:.2f}')","metadata":{"execution":{"iopub.status.busy":"2023-11-05T17:04:15.306170Z","iopub.execute_input":"2023-11-05T17:04:15.306464Z","iopub.status.idle":"2023-11-05T17:04:15.317536Z","shell.execute_reply.started":"2023-11-05T17:04:15.306439Z","shell.execute_reply":"2023-11-05T17:04:15.316598Z"},"trusted":true},"execution_count":158,"outputs":[]},{"cell_type":"code","source":"num_classes = len(np.unique(y_train))\nvocab_size = len(vocab)\nemb_dim = 256\nhidden_dim = 128\ndrop_prob = 0.4","metadata":{"execution":{"iopub.status.busy":"2023-11-05T17:04:15.548716Z","iopub.execute_input":"2023-11-05T17:04:15.549077Z","iopub.status.idle":"2023-11-05T17:04:15.554393Z","shell.execute_reply.started":"2023-11-05T17:04:15.549045Z","shell.execute_reply":"2023-11-05T17:04:15.553426Z"},"trusted":true},"execution_count":159,"outputs":[]},{"cell_type":"code","source":"model_lstm = RNNModel(vocab_size,emb_dim,hidden_dim,num_classes,drop_prob,num_layers=3,bidir=True, seq=\"lstm\")","metadata":{"execution":{"iopub.status.busy":"2023-11-05T17:04:15.868915Z","iopub.execute_input":"2023-11-05T17:04:15.869248Z","iopub.status.idle":"2023-11-05T17:04:15.886156Z","shell.execute_reply.started":"2023-11-05T17:04:15.869217Z","shell.execute_reply":"2023-11-05T17:04:15.885413Z"},"trusted":true},"execution_count":160,"outputs":[]},{"cell_type":"code","source":"train(model_lstm,35)","metadata":{"execution":{"iopub.status.busy":"2023-11-05T17:04:18.302889Z","iopub.execute_input":"2023-11-05T17:04:18.303771Z","iopub.status.idle":"2023-11-05T17:04:40.174426Z","shell.execute_reply.started":"2023-11-05T17:04:18.303733Z","shell.execute_reply":"2023-11-05T17:04:40.173369Z"},"trusted":true},"execution_count":161,"outputs":[{"name":"stdout","text":"IS CUDA:  True\nEpoch [1/35], Loss: 93.29036211967468, Train Accuracy: 0.38  Val Accuracy: 0.00\nEpoch [2/35], Loss: 76.39439451694489, Train Accuracy: 0.00  Val Accuracy: 0.25\nEpoch [3/35], Loss: 66.39456450939178, Train Accuracy: 0.12  Val Accuracy: 0.50\nEpoch [4/35], Loss: 65.37175726890564, Train Accuracy: 0.12  Val Accuracy: 0.38\nEpoch [5/35], Loss: 51.4245787858963, Train Accuracy: 0.38  Val Accuracy: 0.62\nEpoch [6/35], Loss: 47.295558512210846, Train Accuracy: 0.62  Val Accuracy: 0.75\nEpoch [7/35], Loss: 42.337356209754944, Train Accuracy: 0.50  Val Accuracy: 0.62\nEpoch [8/35], Loss: 38.51057821512222, Train Accuracy: 0.75  Val Accuracy: 0.75\nEpoch [9/35], Loss: 32.002619467675686, Train Accuracy: 0.88  Val Accuracy: 0.75\nEpoch [10/35], Loss: 25.300126127898693, Train Accuracy: 0.88  Val Accuracy: 0.75\nEpoch [11/35], Loss: 30.557545766234398, Train Accuracy: 0.88  Val Accuracy: 0.88\nEpoch [12/35], Loss: 24.620021793991327, Train Accuracy: 1.00  Val Accuracy: 1.00\nEpoch [13/35], Loss: 23.897580109536648, Train Accuracy: 1.00  Val Accuracy: 1.00\nEpoch [14/35], Loss: 24.542174018919468, Train Accuracy: 1.00  Val Accuracy: 1.00\nEpoch [15/35], Loss: 24.843457102775574, Train Accuracy: 1.00  Val Accuracy: 1.00\nEpoch [16/35], Loss: 26.87991736456752, Train Accuracy: 1.00  Val Accuracy: 1.00\nEpoch [17/35], Loss: 26.257117153145373, Train Accuracy: 1.00  Val Accuracy: 1.00\nEpoch [18/35], Loss: 26.36306062573567, Train Accuracy: 1.00  Val Accuracy: 1.00\nEpoch [19/35], Loss: 32.81952175265178, Train Accuracy: 0.88  Val Accuracy: 1.00\nEpoch [20/35], Loss: 30.643459259532392, Train Accuracy: 1.00  Val Accuracy: 1.00\nEpoch [21/35], Loss: 29.794406368862838, Train Accuracy: 1.00  Val Accuracy: 1.00\nEpoch [22/35], Loss: 36.91551599930972, Train Accuracy: 0.75  Val Accuracy: 1.00\nEpoch [23/35], Loss: 29.917779573239386, Train Accuracy: 1.00  Val Accuracy: 1.00\nEpoch [24/35], Loss: 26.624564854428172, Train Accuracy: 1.00  Val Accuracy: 1.00\nEpoch [25/35], Loss: 26.20076695550233, Train Accuracy: 1.00  Val Accuracy: 1.00\nEpoch [26/35], Loss: 26.70595208508894, Train Accuracy: 1.00  Val Accuracy: 1.00\nEpoch [27/35], Loss: 31.451387499459088, Train Accuracy: 1.00  Val Accuracy: 0.75\nEpoch [28/35], Loss: 33.184487014543265, Train Accuracy: 1.00  Val Accuracy: 1.00\nEpoch [29/35], Loss: 31.643178624566644, Train Accuracy: 1.00  Val Accuracy: 1.00\nEpoch [30/35], Loss: 32.52589109260589, Train Accuracy: 1.00  Val Accuracy: 1.00\nEpoch [31/35], Loss: 32.183094621868804, Train Accuracy: 1.00  Val Accuracy: 1.00\nEpoch [32/35], Loss: 32.477283943095244, Train Accuracy: 1.00  Val Accuracy: 1.00\nEpoch [33/35], Loss: 32.64950234454591, Train Accuracy: 1.00  Val Accuracy: 1.00\nEpoch [34/35], Loss: 32.64990844868589, Train Accuracy: 1.00  Val Accuracy: 1.00\nEpoch [35/35], Loss: 32.96015700639691, Train Accuracy: 1.00  Val Accuracy: 1.00\n","output_type":"stream"}]},{"cell_type":"code","source":"model_gru = RNNModel(vocab_size,emb_dim,hidden_dim,num_classes,drop_prob,num_layers=1,bidir=True,seq=\"gru\")","metadata":{"execution":{"iopub.status.busy":"2023-11-05T17:04:45.799357Z","iopub.execute_input":"2023-11-05T17:04:45.800248Z","iopub.status.idle":"2023-11-05T17:04:45.810384Z","shell.execute_reply.started":"2023-11-05T17:04:45.800207Z","shell.execute_reply":"2023-11-05T17:04:45.809620Z"},"trusted":true},"execution_count":162,"outputs":[]},{"cell_type":"code","source":"train(model_gru,20)","metadata":{"execution":{"iopub.status.busy":"2023-11-05T17:04:50.470715Z","iopub.execute_input":"2023-11-05T17:04:50.471518Z","iopub.status.idle":"2023-11-05T17:04:57.780150Z","shell.execute_reply.started":"2023-11-05T17:04:50.471484Z","shell.execute_reply":"2023-11-05T17:04:57.779245Z"},"trusted":true},"execution_count":163,"outputs":[{"name":"stdout","text":"IS CUDA:  True\nEpoch [1/20], Loss: 89.13558173179626, Train Accuracy: 0.25  Val Accuracy: 0.25\nEpoch [2/20], Loss: 62.976693868637085, Train Accuracy: 0.50  Val Accuracy: 0.75\nEpoch [3/20], Loss: 37.7839440703392, Train Accuracy: 0.88  Val Accuracy: 0.88\nEpoch [4/20], Loss: 21.78274303674698, Train Accuracy: 1.00  Val Accuracy: 0.88\nEpoch [5/20], Loss: 15.550272047519684, Train Accuracy: 1.00  Val Accuracy: 0.88\nEpoch [6/20], Loss: 11.757794301956892, Train Accuracy: 1.00  Val Accuracy: 1.00\nEpoch [7/20], Loss: 11.023748081177473, Train Accuracy: 1.00  Val Accuracy: 1.00\nEpoch [8/20], Loss: 10.226082149893045, Train Accuracy: 1.00  Val Accuracy: 1.00\nEpoch [9/20], Loss: 9.451268069446087, Train Accuracy: 1.00  Val Accuracy: 1.00\nEpoch [10/20], Loss: 9.404732123017311, Train Accuracy: 1.00  Val Accuracy: 1.00\nEpoch [11/20], Loss: 9.367515539750457, Train Accuracy: 1.00  Val Accuracy: 1.00\nEpoch [12/20], Loss: 8.969753273762763, Train Accuracy: 1.00  Val Accuracy: 1.00\nEpoch [13/20], Loss: 8.627454793080688, Train Accuracy: 1.00  Val Accuracy: 1.00\nEpoch [14/20], Loss: 8.765883422456682, Train Accuracy: 1.00  Val Accuracy: 1.00\nEpoch [15/20], Loss: 8.675057176500559, Train Accuracy: 1.00  Val Accuracy: 1.00\nEpoch [16/20], Loss: 8.853300401940942, Train Accuracy: 1.00  Val Accuracy: 1.00\nEpoch [17/20], Loss: 8.777987859211862, Train Accuracy: 1.00  Val Accuracy: 1.00\nEpoch [18/20], Loss: 8.532450872473419, Train Accuracy: 1.00  Val Accuracy: 1.00\nEpoch [19/20], Loss: 8.620843250770122, Train Accuracy: 1.00  Val Accuracy: 1.00\nEpoch [20/20], Loss: 8.785356636391953, Train Accuracy: 1.00  Val Accuracy: 1.00\n","output_type":"stream"}]},{"cell_type":"code","source":"def make_pred(model,text):\n    text = clean_text(text)\n    # Convert the text to a sequence of word indices\n    text_indices = [vocab[word] for word in text.split()]\n        \n    # padding for same length sequence\n    if len(text_indices)<max_words:\n        text_indices = text_indices + [1]*(max_words - len(text_indices))\n    text_indices = torch.tensor(text_indices).cuda()\n    pred = model(text_indices.unsqueeze(0))\n\n    print(idx2dis[pred.argmax(1).item()])","metadata":{"execution":{"iopub.status.busy":"2023-11-05T17:19:21.643014Z","iopub.execute_input":"2023-11-05T17:19:21.643759Z","iopub.status.idle":"2023-11-05T17:19:21.649583Z","shell.execute_reply.started":"2023-11-05T17:19:21.643725Z","shell.execute_reply":"2023-11-05T17:19:21.648641Z"},"trusted":true},"execution_count":215,"outputs":[]},{"cell_type":"code","source":"symp2 = \"I've been itching a lot, and it's been accompanied with a rash that looks to be getting worse over time. \\\nThere are also some patches of skin that are different colours from the rest of the skin,\\\nas well as some lumps that resemble little nodes.\"\n\nmake_pred(model_lstm, symp2)","metadata":{"execution":{"iopub.status.busy":"2023-11-05T17:19:22.763068Z","iopub.execute_input":"2023-11-05T17:19:22.763423Z","iopub.status.idle":"2023-11-05T17:19:22.772483Z","shell.execute_reply.started":"2023-11-05T17:19:22.763389Z","shell.execute_reply":"2023-11-05T17:19:22.771609Z"},"trusted":true},"execution_count":216,"outputs":[{"name":"stdout","text":"Fungal infection\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Though perfect evaluation score, not reliable due to very small dataset.  \n\n  \n**TODO**\n- Hyperparameter Tuning/Search\n- Test on real data\n- Experiment with/without stopwords removal\n- Use other methods of vectorization (Glove/Word2Vec embeddings)","metadata":{}}]}